{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e2185ba-cfa1-493a-8d39-dda3d0e641f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breathe-india-covid-19-effect-on-pollution Perform a comprehensive data analysis to assess the impact of COVID-19 lockdown on air pollution levels in India. This includes a time trend analysis of air pollutant concentrations from 2015 to 2020 and a comparative study of pollution levels before, during, after the lockdown, and in equivalent months of the previous year (2019). Ensure to preprocess the data by formatting the Date column into DateTime format and handling missing values appropriately. Utilize appropriate visualizations and statistical methods to support the analysis. Key pollutants to examine include PM2.5, PM10, NOx, SO2, CO, BTX, NH3, and O3. Metrics to be evaluated can include mean, median, and standard deviation of pollutant concentrations, as well as any significant changes observed during the specified periods.\n",
      "__________\n",
      "where-to-invest-to-combat-air-pollution-in-india Identify and prioritize cities for investment to reduce air pollution based on data analysis of the air quality in over 25 Indian cities provided in the dataset, and develop a data-driven recommendation for a monetary investment strategy targeting air quality improvement. The analysis should select a maximum of three cities, provide evidence to convince an investor, and describe indicators to measure the effectiveness of the investments.\n",
      "__________\n",
      "melbourne-comprehensive-housing-market-analysis Analyze the house prices in Melbourne to determine the most expensive sectors, the price increase over the years, and any seasonal patterns in sales volume. Include data cleaning to remove rows with null values, employ Gaussian distribution for outlier detection, convert date columns to datetime, and create additional columns for months and years. Use plotly for visualization, including violin plots to show price distribution across seasons, and compare sales activity by month for different years.\n",
      "__________\n",
      "industrial-accident-causal-analysis Conduct a technical analysis of the industrial accident dataset including Exploratory Data Analysis (EDA), feature engineering, and modeling using LightGBM. Apply Natural Language Processing (NLP) for text data preprocessing and feature extraction, such as lower-casing, lemmatizing, stemming, removing stopwords, and computing TF-IDF. Perform sentiment analysis on textual descriptions. Extract time-related features from available timestamps. Use visualization libraries (bokeh via holoviews preferred) to elucidate data characteristics. Investigate the causes of accidents through causal analysis and quantify the severity (Accident Level and Potential Accident Level). Evaluate the models using appropriate performance metrics.\n",
      "__________\n",
      "analyzing-editors-descriptions-hidden-gems Perform sentiment analysis on Martin's notebook descriptions from his 'hidden gems' posts, and quantify their similarity. Calculate the distribution parameters for negative, positive, and neutral sentiments, and vectorize the descriptions to compute the pairwise L1 norm to generate a clustered heatmap visualizing similarities and differences between the descriptions. Report the measures of central tendency (mean) and spread (standard deviation) for sentiment distributions, and describe the pattern of description similarities based on the heatmap.\n",
      "__________\n",
      "the-math-of-the-neuron-with-animation Implement a single neuron model with sigmoid activation in a machine learning context. Formulate forward propagation to predict outcomes, compute the cost function using binary cross-entropy loss, and perform backward propagation using gradient descent to update weights and biases. Calculate partial derivatives of the cost function with respect to each weight and bias.\n",
      "__________\n",
      "bgg-ratings-mechanics-miniatures Examine the relationship between board game rankings and the number of voters, analyzing how game ownership categories and voter count bins affect average user ratings and Geek Ratings. Subsequently, investigate the influence of board game categories and mechanics on ratings. Implement metrics for correlational analysis and statistical significance between the variables.\n",
      "__________\n",
      "food-feed-facts Perform data cleaning on the Open Food Facts dataset, including the removal of empty rows and columns, elimination of redundant variables, standardization of country data, extraction and analysis of keywords in the 'categories_en', 'pnns_groups_1', and 'pnns_groups_2' variables, and evaluation of the filling factor and dispersion of product content. Then, assess the quality of food types based on correlations, nutrition grade, and nutrient content.\n",
      "__________\n",
      "a-heatmap-roadmap-to-your-dream-job Analyze the 2020 Kaggle ML & DS Survey to determine the day-to-day activities associated with different job titles in the field of machine learning and data science. Exclude respondents who are students, currently not employed, or have undefined 'Other' job titles. Also, discard entries with missing or very low yearly compensation (less than $1000 USD), and only consider job titles with more than 100 respondents to ensure sufficient sample size for reliable analysis.\n",
      "__________\n",
      "gender-pay-gap-a-myth-or-a-reality Analyze the 2020 Kaggle Machine Learning & Data Science Survey dataset to assess the existence and extent of a gender pay gap within the data science and machine learning community. Use appropriate statistical methods to compare the earnings of men and women and report findings in the context of gender disparities in technology roles. Metrics to be used include mean/median salary comparison, pay distribution analysis, and potentially regression models to adjust for confounding factors.\n",
      "__________\n",
      "does-twitter-chirp-chai Examine the correlation between Twitter metrics (likes and retweets termed as 'twitter_reactions', and interviewee follower count) and CTDS episode views to determine the impact of Twitter on the viewership. Include analysis for both individual episodes and podcasts. Metrics to consider: correlation coefficient, R-squared value or other statistical measures of association.\n",
      "__________\n",
      "complete-visualization-and-analysis-of-2020debates Perform data cleaning and transformation on debate transcripts dataset by checking for null values, standardizing names of debaters and mediators, and reformatting the 'minute' column to a consistent time frame for analysis. Subsequently, calculate time differences between speech segments to create a continuous timeline. Generate heatmaps to visualize the frequency and intensity of interruptions during the debates, identifying key moments of heightened interaction. Quantify the 'heat' of discussions using a suitable metric, such as the number of interruptions per time segment. Tools to be used may include pandas for data manipulation and seaborn or matplotlib for heatmap visualization.\n",
      "__________\n",
      "who-s-not-here-kaggle-user-survey-2020 Analyze the first five columns (Q1-Q5) of the 2020 Kaggle user survey to determine the characteristics of underrepresented groups in the dataset with respect to age, gender, country of residence, level of formal education, and occupation title. Determine metrics for underrepresentation within each demographic.\n",
      "__________\n",
      "how-was-the-growth-of-kaggle-insightful-approach Analyze the Meta-Kaggle dataset to compute the following: total number of users registered on Kaggle, count of active users, distribution of user tiers, the date when Kaggle reached 1 million registrations, the average daily rate of registrations, the highest number of registrations in a single day, and the average time taken for users to achieve different tiers.\n",
      "__________\n",
      "deep-sea-dive-into-top-10-survival-guide None\n",
      "__________\n",
      "egyptian-endeavour-moment-of-truth Analyze the success of governmental educational initiatives in Egypt targeting data science and programming skills. Utilize Kaggle survey datasets from 2019, 2020, and 2021 to compare the year-over-year change in the number of Egyptian participants, specifically those with less than three years of coding experience.\n",
      "__________\n",
      "time-series-transformations {'description': 'Apply data transformations to a time series dataset to stabilize variance and achieve stationarity before using statistical or machine learning models. Implement and validate inverse transformations to ensure the original data scale is available for interpretation. Specifically, execute power transformations (e.g., square root, cube root, logarithmic, and Box-Cox) and difference transformations for trend removal. Choose the optimal lambda for Box-Cox using the guidelines for normal distribution approximation. Utilize pandas for differencing and manage NaN values accordingly.', 'transformations': ['Square root', 'Cube root', 'Logarithmic', 'Box-Cox'], 'optimization_metric': 'Lambda for Box-Cox', 'differencing_order': 'First or higher-order differencing', 'inverse_requirements': 'Properly handle cumulative sums and last known observations for inverse differencing', 'software': 'pandas'}\n",
      "__________\n",
      "loan-classification-detecting-credit-defaults Conduct a data science project to predict loan repayment defaulting, incorporating an extensive exploratory data analysis to understand influential factors, preprocessing of data to address missing values and scaling, and the implementation of an appropriate predictive model. Examine the distribution of variables and their skewness, analyze gender differences in relation to loan defaults, and identify key features for improving prediction accuracy. Employ statistical techniques, such as the scipy 'norm' function and natural logarithm transformation, to achieve normally distributed features. Evaluate model fit and performance using relevant metrics.\n",
      "__________\n",
      "kiva-in-2-minutes-animated-story Build localized models to estimate the poverty levels of residents in regions where Kiva has active loans using their loan distribution and multipurpose poverty index (MPI) data. Assess model performance based on appropriate evaluation metrics such as Mean Squared Error (MSE), R-squared, or any other relevant metric for regression analysis.\n",
      "__________\n",
      "plotly-analyzing-why-do-space-missions-fail Perform exploratory data analysis to investigate the factors contributing to space mission failures. Analyze the relationships between mission outcome and variables such as launch location, company, launch vehicle, launch timing, and mission cost. Model the likelihood of mission success or failure and identify key feature importances.\n",
      "__________\n",
      "rfcx-fastai-trick-to-load-spectrogram-fast Implement a data pre-processing pipeline that transforms audio recordings into mel-spectrograms and saves them to disk. The pipeline should (1) extract 10-second clips centered around labeled species occurrences, (2) perform audio augmentation using `ResizeSignal` to crop 8-second clips and `AddNoise`, and (3) save each augmented sample to disk with a unique filename pattern `{recording_id}_{t_min}_{t_max}_{index}.pt`. The augmentation should be bootstrapped `RESAMPLE_N` times to create diverse snapshots. Measure and compare the data loading speed with and without using precomputed mel-spectrograms.\n",
      "__________\n",
      "divorce-prediction-with-rf Apply machine learning interpretability techniques to a RandomForest model to understand feature relationships and their effects on the model's predictions.\n",
      "__________\n",
      "cropland-mapping-random-forest-neural-network Develop a crop mapping model using Random Forests and Neural Networks to classify land cover based on a fused optical-radar dataset. Evaluate the model performance using appropriate metrics such as accuracy, precision, recall, and F1-score.\n",
      "__________\n",
      "fastai-multi-core-tpu-pets-sample None\n",
      "__________\n",
      "ml-and-kaggle-a-hardware-lottery Analyze the impact of hardware accessibility on the success of ML research, industry, and Kaggle competitions by exploring Kaggle survey data to determine the usage of various computing platforms and the frequency of TPU utilization, comparing the rate of TPU usage between 2020 and 2019.\n",
      "__________\n",
      "discussion-hotness-plots Develop an algorithm to correctly order discussion posts by 'Hotness', which should take into account factors such as the age of the post, vote count, and comment count. The algorithm should ensure that new posts are prominently displayed initially and then ranked based on interaction metrics. Implement a time decay factor for the 'Hotness' metric to reflect the natural decline in visibility over time. Validate the algorithm using the provided dataset of 10,000 discussion posts, ensuring that posts are not getting queued erroneously. Evaluate the performance of the algorithm using suitable metrics like Mean Reciprocal Rank (MRR), Precision at k (P@k), or Normalized Discounted Cumulative Gain (NDCG).\n",
      "__________\n",
      "arxiv-taxonomy-e-top-influential-papers Develop a data analysis pipeline to explore and visualize the arXiv taxonomy and identify the most influential articles in each arXiv field by counting the citations received from other papers within the arXiv repository. Output should include visualizations of the taxonomy and a ranked list of articles by citations per field. Use appropriate metrics for influence, such as citation count.\n",
      "__________\n",
      "learning-in-cyberspace-a-story-of-pandemic-times Analyze the trends and factors affecting digital learning engagement in the United States during 2020, focusing on the standardized engagement index and percentage access across different time frames (including weekends, holidays, and pre/post-arrival of COVID-19), and explore the varying engagement levels of different educational technology products over the course of the pandemic. Metrics to include are the standardized engagement index, percentage access, and correlations between these metrics and the timing of COVID-19's impact on digital learning.\n",
      "__________\n",
      "air-pollution-101 Extract average Air Quality Index (AQI) for each pollutant by county in the United States for the year 2016. This requires performing a GROUP BY operation on the 'county' attribute, and joining the resulting datasets for all pollutants.\n",
      "__________\n",
      "q-and-a-with-google-play-store-data Perform exploratory data analysis on the Google Play Store Apps dataset to determine in which app category a developer is likely to generate more revenue by releasing a paid app as opposed to a free app. Compare the market size and potential profitability between paid and free app categories, and explore underlying factors influencing the prevalence of paid apps.\n",
      "__________\n",
      "kaggle-discussions-busiest-time-of-the-day Fit two Gaussian functions to model the curve of the number of Comments on Kaggle discussions, using the SciPy optimize.curve_fit routine. Determine the full width at half maximum (FWHM) of both Gaussians, the ratio of the peaks' heights, and the separation period between the two peaks in hours.\n",
      "__________\n",
      "what-s-this-chai-and-datascience Analyze the 'Chai Time Data Science' dataset to gain insights from the 100+ interviews with machine learning heroes. This includes exploration and potential analysis of various components such as episode statistics, YouTube descriptions, thumbnail types, and subtitles (both raw and cleaned). Metrics and methodologies may pertain to data cleaning, exploratory data analysis, pattern recognition, sentiment analysis, and any relevant statistical analysis to uncover trends or interesting findings in the data.\n",
      "__________\n",
      "kaggle-story-b-c-before-covid-and-through Analyze and compare the time taken to complete a survey by respondents, focusing on how this time is distributed across different genders and age groups. Identify outliers, especially among younger respondents, and investigate changes in the occurrence of outliers across surveys from different years. Additionally, assess demographic shifts over the past three years, evaluating the representation of countries across the surveys and noting any additions or dropouts of countries in this dataset.\n",
      "__________\n",
      "ranzcr-1st-place-soluiton-cls-model-small-ver Train a 5-fold classification model using 5-channel input (3 channels from original image and 2 channels from predicted segmentation masks) with EfficientNet architectures (B3-B5 for classification, B5-B7 for segmentation if needed). Do not use external data. Achieve a cross-validation (CV) score between 0.968 and 0.969 and a leaderboard score around 0.972. Apply optimized augmentations, AMP, Cross-Entropy loss for ETT tube, a warmup phase, and a cosine scheduler for training. Train each fold for 30 epochs.\n",
      "__________\n",
      "covid-19-study-with-epidemiology-models Formulate and program SIR, SEIR, SIRD, SEIR-2, SEIRD, and SEIRD-Q epidemiology models to fit and predict COVID-19 spread in a given territorial area, incorporating data cleaning and basic exploratory data analysis (EDA) as preliminary steps. Assess model accuracy using least-squares or Bayesian calibration. Models should consider disease mortality, transmission during incubation, and quarantine effects, and be adjustable based on local data.\n",
      "__________\n",
      "covid19-statistical-analysis-in-germany Analyze the COVID-19 dataset for Germany focusing on the following: 1) normalization of cases and deaths per population and population density per state, 2) calculation of the time-varying infection rate and doubling time across different pandemic periods, and 3) assessment of age and gender distribution among infected individuals. Ensure geographical analysis using Lambert Azimuthal Equal Area projection for area-conserving visualizations. Calculate state areas for density measurements from geometry data and convert to square kilometers.\n",
      "__________\n",
      "big-macs-rock-stars-what-seperates-top-earners Conduct an analysis to determine how professional salaries vary by location using the 2021 Kaggle Data Science survey dataset. Include a distribution analysis of overall income, filtered to exclude students and those with an income of $0. Then, analyze the salary distribution specifically by country, focusing on the 10 countries with the most respondents, and record salaries from binned ranges as their lower bound. Calculate the median income for each country, and compare it to the United States' median salary by creating bands based on percentage proximity to this reference salary. Additional assessment of relative purchasing power of income by country may also be required.\n",
      "__________\n",
      "getting-started-with-biopython Implement a parser using the Biopython library to extract the first 6 sequences from a genomic dataset file, ensuring compatibility with the file's biological data format and handling any format subtleties or irregularities.\n",
      "__________\n",
      "the-reason-we-re-happy Analyze the World Happiness Report dataset to identify how various features correlate with happiness scores using Spearman correlation coefficients and pairwise comparisons. Construct a predictive model using random forests to evaluate the importance of features in predicting happiness scores. Ensure to handle different naming conventions in the dataset for consistency across years. Address issues of potential data skewness and subjectivity as highlighted in the text. Evaluate the auto-correlation of the 'Trust' feature. Exclude 'Happiness', 'Whisker', and 'Dystopia.Residual' features as they are target variables.\n",
      "__________\n",
      "treasure-hunt-what-gives-to-be-really-good Identify and analyze the subgroup of Kaggle survey respondents based on their ability to purchase McMeal menus using their own country's purchasing power. Normalize salary indications across different countries by calculating the number of McMeals each respondent could buy with their annual salary. Segment the normalized McMeal purchase power into three categories - High, Very High, and Crazy High - based on the number of McMeals that can be purchased, using thresholds of 10,000, 20,000, and 50,000 units respectively, and quantify the number of respondents in each category. Report the findings, considering regional cost-of-living differences as an indicator of data science success.\n",
      "__________\n",
      "upit-a-package-for-unpaired-img2img-translation Train a CycleGAN model for unpaired image-to-image translation using the UPIT fastai/PyTorch package, incorporating a ResNet-block-based architecture for the generator and a 70x70 PatchGAN for the discriminator. Evaluate the model using Frechet Inception Distance (FID) metric and track experiments with Weights and Biases.\n",
      "__________\n",
      "explore-ml-ds-survey-2021-ukraine Analyze the Machine Learning and Data Science Survey dataset to examine the subset of records pertaining to professionals from Ukraine.\n",
      "__________\n",
      "data-heroines-saving-the-world-through-data None\n",
      "__________\n",
      "is-a-vaccinated-country-a-happy-one-data-analysis Develop and execute a data preprocessing pipeline for two datasets, including missing value treatment, deduplication, and validation of key columns for merging. Implement descriptive statistics to summarize the datasets. Prepare the data for further analysis with the objective of creating a predictive model to estimate vaccination rates by country as of June 30, 2021, in relation to various socioeconomic factors from the World Happiness Report. Determine the key determinants of vaccination rates across different countries.\n",
      "__________\n",
      "identifying-bias-in-ai Identify and analyze bias in a real-world dataset through a hands-on exercise, focusing on historical, representation, measurement, aggregation, evaluation, and deployment biases.\n",
      "__________\n",
      "mapping-poverty-around-the-world Develop localized models to estimate the poverty levels of residents in the regions where Kiva has active loans using Kiva's regional mappings of Multidimensional Poverty Index (MPI) and relevant metrics like population growth, access to healthcare, malnutrition prevalence, sanitary conditions, access to education, Global Peace Indicator, and World Happiness Index. Address data quality issues by identifying and handling regions with incorrect coordinates.\n",
      "__________\n",
      "tweet-sentiment-extraction-pytorch Develop a PyTorch-based solution for the extraction of support phrases corresponding to sentiment labels within Tweets, using a RoBERTa model fine-tuned for this specific task. Measure the performance using appropriate evaluation metrics for the extraction task, which may include F1-score, Exact Match (EM), and/or Jaccard similarity.\n",
      "__________\n",
      "2ndplace-solution None\n",
      "__________\n",
      "visualizing-convolution-filters Perform Exploratory Data Analysis (EDA) visualizations specific to Convolutional Neural Network (CNN) filters for an Image Recognition project.\n",
      "__________\n",
      "space-missions-tech-race-space-theme-plots Create a series of data visualizations representing the global distribution of space companies, distinguishing between private and government entities. Visualize the correlation between launch vehicle power and their payload carrying capacity, and map the payload dimensions to the different fairing sizes offered by various companies. Include visualizations differentiating between geostationary transfer orbit (GTO) and low Earth orbit (LEO) missions, highlighting the energy requirements, bandwidth, and communication latency characteristics. Metrics should be chosen to quantitatively describe launch vehicle power, payload dimensions, and orbital characteristics.\n",
      "__________\n",
      "food-nutrition-analysis-eda Perform data cleaning on a dataset containing common available foods and their nutritional facts, preparing it for exploratory visualizations with Plotly and Matplotlib. Include identification and handling of missing values, data type adjustments if necessary, and any anomaly corrections to ensure data quality for subsequent analyses.\n",
      "__________\n",
      "starting-point-big-query-and-london-crime Extract data from the 'crime_by_lsoa' table in the Big Query 'london' database using SQL commands for initial exploration. Perform basic data visualization to gain insights into the dataset. Use BQ Helper or a similar package to connect to the database, read data into Python, and visualize the initial rows of the dataset.\n",
      "__________\n",
      "tps-01-21-feature-importance-with-xgboost-and-shap Calculate SHAP values for feature importance on a test dataset using a GPU-enabled XGBoost 1.3+ to leverage computational speedup. Subsequently, visualize the computed SHAP values through plots.\n",
      "__________\n",
      "efficientdet-meets-pytorch-lightning Train an object detection model using EfficientDet architecture on the global wheat competition dataset, evaluating performance using the competition's specified evaluation metric.\n",
      "__________\n",
      "alzheimer-mri-model-tensorflow-2-3-data-loading Build a convolutional neural network (CNN) using `tf.keras` to classify MRI images into 4 classes representing different levels of dementia in Alzheimer's patients, with an emphasis on achieving a high ROC AUC score as the evaluation metric.\n",
      "__________\n",
      "eda-of-murders-in-india Analyze historical murder victim data in India to identify trends in the number of murder victims over the years and categorize the victims by state and age group. Data spans from 2001 to 2010 and includes 35 states & Union territories with victims sorted into six age categories: <10, 10-15, 15-18, 18-30, 30-50, and 50+. Track the homicide rate and provide visualizations of the trend. The analysis should measure the homicide rate per 100,000 population and include any noticeable trends in the data.\n",
      "__________\n",
      "ad-clicks-eda-classification Perform demographic analysis focused on age and gender by creating age bins for the 18-25 range, analyzing click-through rates by gender, and correlating salary data with both gender and age groups. Use appropriate statistical measures to assess relationships, such as correlation coefficients for continuous variables and calculate aggregate metrics (e.g., mean, median) for salary within categories.\n",
      "__________\n",
      "cricket-analytics-decoding-stories None\n",
      "__________\n",
      "avocado-eda Perform exploratory data analysis (EDA) and apply machine learning (ML) methods to investigate avocado prices using the provided dataset, which includes average price, type, year, region, and total volume, as well as PLU-specific sales numbers. Include steps such as data preprocessing (handling outliers, renaming columns, and changing data types), feature examination, and creating a correlation matrix. Apply regression analysis to determine factors contributing to avocado price variations and predict prices.\n",
      "__________\n",
      "we-are-from-our-childhood Perform exploratory data analysis to investigate differences between participants who spent most of their childhood in rural versus urban areas, followed by logistic regression to determine the impact of living area on various outcome variables. Specify and report relevant metrics such as accuracy, precision, recall, or AUC for the logistic regression model.\n",
      "__________\n",
      "australia-on-fire-animation Create an animation using Plotly to visualize the scale of the Australian wildfires that have been occurring since July 2019 from the provided dataset.\n",
      "__________\n",
      "industrial-machine-anomaly-detection Develop a data science pipeline for anomaly detection on industrial machine data, including data preprocessing, exploratory data analysis (EDA), visualization, and modeling using various techniques such as Hotelling's T2, One-Class SVM, Isolation Forest, LOF, ChangeFinder, and a variance-based method. Improve model interpretability using tools such as SHAP. Benchmark and compare model performance on machine_temperature_system_failure dataset from the NAB-dataset. Ensure models handle time-series data effectively.\n",
      "__________\n",
      "is-social-distancing-changing-our-kaggle-habits None\n",
      "__________\n",
      "let-s-respect-the-veterans Analyze the distribution of coding experience among Kaggle survey respondents, focusing on comparing two groups: 'novices' with 1 year or less of coding experience and 'veterans' with 20 or more years of coding experience. Identify and quantify the skill differences between these groups and determine the skills in which veterans are more proficient. Calculate the skewness of the programming experience distribution and the proportion of these two groups within the survey population.\n",
      "__________\n",
      "music-generation-lstm Develop a recurrent neural network (RNN) using LSTM (Long Short-Term Memory) for music generation by training it on a dataset of MIDI files of classical piano music, specifically the compositions of Frédéric Chopin. Extract and preprocess the musical notes and chords from the MIDI files to create a corpus for training. The trained model should predict the next note or chord sequence in a given musical piece. Evaluate the model's performance using appropriate music generation metrics.\n",
      "__________\n",
      "time-series-forecasting-building-intuition Formulate and execute a Time Series Forecasting problem, involving a univariate dataset where input sequence is equal to output sequence. Predict the next 5 timesteps based on a fixed size input window. Implement a sliding window approach with a step size of 20 for generating datasets for training and testing the model. Evaluate the model using appropriate forecast accuracy metrics such as MAE, MSE, RMSE, or MAPE.\n",
      "__________\n",
      "unbiased-look-on-brazil-wildfires Perform a descriptive analysis of Brazil's wildfires over a 20-year period (1998-2017) including data visualization for trend analysis and state-wise fire frequency, with a special focus on evaluating the trend in the Amazon State to determine whether it follows an increasing trend or resembles a random walk. Use appropriate summary statistics and visualizations to illustrate the temporal distribution of fires, and compare the frequency of wildfires in the Amazon State to overall trends.\n",
      "__________\n",
      "ama-with-a-data-scientist Analyze survey responses from Data Scientists to answer fundamental questions about the field of Data Science, tools and techniques used, domains of expertise, and guidance for non-CS background individuals aspiring to enter the field. Include analysis of the increase in demand for Data Scientists based on provided interest trends over time and graph analysis to illustrate the role of diverse skills in Data Science.\n",
      "__________\n",
      "ctds-subtitles-exploration Perform data preprocessing and feature engineering on the subtitle dataset. Aggregate the provided CSV files for database-like analysis, generate new features from subtitle data, explore speaker-related metrics, and identify and clean bad data. Implement basic NLP analysis without the use of advanced models or toolkits.\n",
      "__________\n",
      "what-gets-you-a-home-loan-in-washington Analyze the 2016 Home Mortgage Disclosure Act (HMDA) dataset for Washington to identify patterns in the mortgage lending process.\n",
      "__________\n",
      "rain-in-australia-with-eda-h2o-88-4-auc Predict whether it will rain in Australia using a classification model after data preprocessing which includes handling missing values, exploratory data analysis, and employing H2O classification algorithms. Evaluate and select the best-performing model.\n",
      "__________\n",
      "nifty-data-eda Explore the NIFTY-50 dataset and its sectoral indices, visualize the datasets to extract important information, and handle any missing values encountered.\n",
      "__________\n",
      "the-learning-gap Analyze school district-level student engagement data from LearnPlatform based on racial diversity and economic factors. Examine how the average online engagement varies according to the percentage of black and Hispanic students within a district. Investigate anomalies in the 80-100% black/Hispanic group, accounting for potential outliers and state-wise differences. Consider additional variables such as per-student spending and state education policies that may influence engagement. Metrics: average engagement scores, student racial demographics, state-wise engagement comparison.\n",
      "__________\n",
      "0-525-tabular-xgboost-gpu-fft-gpu-cuml-fast None\n",
      "__________\n",
      "evolution-of-social-complexity-a-data-analysis Extract and encode relationships between rituals and social complexity using the SESHAT database, testing the five predictions derived from the 'Divergent Modes of Religiosity'. Evaluate conformity to collective values through indicators of ritual performance, assessing the impact on social group integration and solidarity. Apply appropriate data science techniques to this historical social dataset and report on findings using relevant metrics, such as correlation coefficients or measures of societal integration.\n",
      "__________\n",
      "the-journey-of-an-image-through-a-neural-network Implement a data science task to visualize the journey of an image through a simple neural network using the MNIST dataset. This task includes building a single-layer network without hidden layers to predict digits from 28x28 pixel greyscale images. The network will use a flatten layer to convert images to vectors of size 785, followed by a dense output layer with ten nodes, one for each digit. Apply the softmax function for the output layer. Integrate the 'NetworkVisualiser' class to produce network visualizations, ensuring it is initialized with the appropriate layers for the MNIST dataset. The performance metric for evaluation will be classification accuracy.\n",
      "__________\n",
      "exploring-global-inequality-and-growth None\n",
      "__________\n",
      "pakistan-s-rising-data-science-2021 Perform a comparative analysis of Pakistan's data science community by comparing the key characteristics, tools, platforms, and demographics of the data science community in Pakistan against the global data science landscape using the Kaggle's Machine Learning and Data Science Survey 2021 dataset. Metrics to analyze could include the number of respondents by country, demographic statistics, preferred technologies and platforms, education levels, company size, programming language preferences, learning resources utilization, machine learning methods adoption in production, and growth trends over time.\n",
      "__________\n",
      "amazon-bestselling-books-eda-and-price-prediction Perform exploratory data analysis focusing on numeric variables distributions and conduct a year-based analysis to assess trends over time. Check for and handle missing values in the dataset.\n",
      "__________\n",
      "time-series-analysis-forecast-with-visualization Perform exploratory data analysis on border crossings time series data to determine trends, seasonality, and unusual spikes or drops. Then, build a forecasting model using SARIMAX to predict future entries. Examine the data for variations across different borders and states, assess the most common entry types, and analyze any potential impacts of presidential terms on total entries. Use appropriate visualizations to support the analysis and select relevant performance metrics for the SARIMAX model, such as Mean Absolute Error (MAE), Root Mean Square Error (RMSE), or Mean Absolute Percentage Error (MAPE).\n",
      "__________\n",
      "feedback-nn-train None\n",
      "__________\n",
      "how-to-get-a-promotion-101 Develop a data preprocessing and feature engineering pipeline for an HR analytics dataset. Task includes handling missing values by setting 'previous_year_rating' to 0 for employees with zero years of service, imputing 'education' column using forward and backward filling methods, creating a new 'Employee_type' column to differentiate new employees from seniors, and generating a new feature representing the age at which the employee was hired. Ensure that the new features are suitable for visualization and comparison in relation to employee promotion eligibility. Metrics were not explicitly mentioned, so default metrics such as accuracy or F1-score for classification could be considered for evaluating promotion prediction models.\n",
      "__________\n",
      "default-of-credit-card-eda-catboost-w-ft-eng 1. Conduct an Exploratory Data Analysis (EDA) to: a) Analyze feature distribution; b) Investigate the association between demographic features and credit amount per customer; c) Assess the probability of default across different feature categories. 2. Implement and evaluate predictive models using 20% of the dataset as a test set. The models to be used are: a) Random Forest for baseline performance; b) CatBoost; c) CatBoost with supplementary features derived from the EDA. 3. Measure the influence of each feature on the prediction outcome applying: a) Feature Importance analysis; b) SHAP (Shapley Additive exPlanations) values.\n",
      "__________\n",
      "football-transfers-2000-2018 Analyze the football transfer market dataset to identify the top 5 leagues based on the turnover from selling players, and the top 5 leagues based on the turnover from buying players. Determine the overall profit for each league by calculating the difference between buying and selling turnover.\n",
      "__________\n",
      "titanic-machine-learning-from-disaster-eda Predict passenger survival on the Titanic using a machine learning model. Evaluate the model's accuracy.\n",
      "__________\n",
      "earthquakes-and-tectonic-plates-seismic-analysis Conduct a geospatial analysis to investigate the correlation between the global distribution of earthquakes and the tectonic plate boundaries. Include appropriate visualizations to support the analysis.\n",
      "__________\n",
      "what-s-going-on-in-ecuador-splash-of-plotly Analyze temporal trends in temperature data across various global regions, assess the magnitude of temperature increase in different countries and cities over time, and identify seasonal temperature patterns and their changes. Evaluate temperature rise metrics and seasonality indicators using visualization tools such as Plotly for interactive data exploration.\n",
      "__________\n",
      "disparity-in-engagement-in-digital-learning Perform an exploratory data analysis to investigate disparities in student engagement between the most and least engaged school districts. This includes calculating the daily average engagement index for each district, determining the most and least engaged districts based on this metric, and quantifying the disparities between these groups in terms of engagement index, number of unique learning products used, per-pupil total expenditure (ppt_total_raw), and demographic metrics (pct_black/hispanic, pct_free/reduced). Calculate Pearson correlation coefficients between these metrics and the engagement index. Additionally, analyze unemployment rates and education levels for the locales of the districts, and provide recommendations to increase student engagement based on these analyses.\n",
      "__________\n",
      "cassava-leaf-disease-vit-tpu-training Train a Visual Transformer (VIT) model for the Cassava Leaf Disease Classification 2020 competition, aiming to maximize performance as measured by accuracy, with a target to surpass 91.3% on both public and private leaderboards.\n",
      "__________\n",
      "find-where-i-truly-belong Perform exploratory data analysis (EDA) to identify patterns, trends, and anomalies within a dataset.\n",
      "__________\n",
      "a-story-about-unsupervised-learning Apply dimensionality reduction methods (PCA, t-SNE, UMAP, TriMap, PaCMAP) and clustering/ outlier detection algorithms (Isolation Forest, Autoencoders, DBSCAN) to the Red Wine Quality dataset, the ModelNet40 dataset, and the MNIST dataset. Normalize the data prior to application of these methods. For time series outlier detection, use the same methods on the Numenta Anomaly Benchmark (NAB) dataset, and additionally apply an Autoencoder LSTM and a Kernel Density Estimator (KDE). Ensure to compare the performance of these methods in the context of the tasks.\n",
      "__________\n",
      "kfc-vs-mc-donalds-vs-cafe-coffee-day Compare the number of outlets for KFC, McDonald's, and Cafe Coffee Day in Bangalore to determine which fast food chain is the most popular. Visualize the distribution of outlets on a map with interactive markers displaying the count per location. Allow users to toggle between the chains’ outlet displays.\n",
      "__________\n",
      "brain-failure-prediction Develop a predictive model to estimate the probability of suffering a stroke based on predictor variables. Explore if factors such as age, heart disease, BMI, and glucose levels have a significant relationship with stroke occurrence. Perform Exploratory Data Analysis (EDA) to understand variable distributions and relationships. Encode categorical features (if not already encoded), visualize distributions with respect to the target variable, and apply machine learning models such as Logistic Regression, Random Forest, and XGBoost. Evaluate the models' performance using appropriate metrics, and streamline the data science workflow from data understanding to final prediction.\n",
      "__________\n",
      "competitiveness-and-expertise-in-tennis {'1': 'Quantitatively analyze the difference in competitiveness between Grand Slam and Non-Grand Slam tennis tournaments by comparing upset frequencies and examining potential causes.', '2': 'Investigate the impact of playing surface on player performance and determine the correlation of performance across different surfaces.', '3': 'Control for match format (best of 5 sets vs best of 3 sets) to assess whether Regular tournaments exhibit higher competitiveness than Grand Slams at the set level, and examine the probability of upsets across different sets within both Grand Slam and Regular tournaments.'}\n",
      "__________\n",
      "logbook-analysis-and-weather-prediction Implement a simple Neural Network using Theano to predict weather patterns from Ocean Ships Logbooks data. Focus on evaluating the model's prediction capabilities given the limited dataset from logbooks. Use appropriate performance metrics suited for weather prediction such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), or any other relevant metric for continuous data regression tasks.\n",
      "__________\n",
      "visual-journey-through-world-development-1985-2015 Transform and merge multiple datasets into a unified format, structured as country-year pairs. Ensure each pair includes a column for each indicator. Implement the following data pre-processing steps: 1. Perform a left join on the country-year pairs from the Country Population dataframe with additional datasets. 2. Convert wide-formatted dataframes into a long format using the pandas melt function. 3. Consolidate the separate indicators in the suicides dataset into a single indicator per age range. 4. Calculate the mean of obesity prevalence estimates from the obesity dataset. Output the final merged dataframe.\n",
      "__________\n",
      "2nd-place-solution Develop models to compute similarity scores for various data types: (1) image similarity using suitable image processing techniques, (2) multi-modal similarity integrating different types of data (e.g., text and images), and (3) textual similarity using BERT embeddings. Implement Query Expansion (QE) methods for image data, multi-modal data, and BERT embeddings. Evaluate the performance using appropriate metrics such as Mean Reciprocal Rank (MRR) or Precision@k for the query expansion tasks.\n",
      "__________\n",
      "monet-visualization-and-augmentation Perform exploratory data analysis on image data which includes visualizing images using matplotlib, constructing graphs for the images, and implementing various image augmentations such as Blur, CLAHE, ChannelDropout, Crop, Flip, GaussNoise, etc. Metrics are not specified.\n",
      "__________\n",
      "i-d-like-to-propose-a-toast-beer-recipes-eda Analyze the Brewer's Friend Beer Recipes dataset to identify the most popular homemade beer styles by quantifying occurrences within the data. Handle missing values by eliminating or imputing, focusing on ensuring the 'Style' column is complete. Utilize metrics such as count frequency to determine popularity.\n",
      "__________\n",
      "forecast-with-n-beats-interpretable-model Implement and tune an interpretable N-BEATS model for time series forecasting. Utilize the model's capacity to describe a series in terms of trend and seasonality. Adjust the implementation to integrate additional components. Apply the quantile loss function for prediction interval estimation, while modifying it to prevent the zeroing of weights by squaring the error. Evaluation metrics to consider include MAPE, SMAPE, MASE, OWA, and Quantile loss.\n",
      "__________\n",
      "petfinder-pawpularity-eda-fastai-starter Develop a machine learning model to predict the 'pawpularity' score of pets using provided images and metadata. The model performance should be evaluated using the Root Mean Square Error (RMSE) metric.\n",
      "__________\n",
      "tpu-sherlocked-one-stop-for-with-tf Set up and iterate through a variety of deep learning experiments using the HuggingFace models with Tensorflow suitable for the 'Contradictory, My Dear Watson' dataset, focusing on templatizing code, tweaking hyperparameters, random seeds, data splits, accelerators, and learning rate schedulers. Measure the success of experiments using the appropriate competition or project metrics.\n",
      "__________\n",
      "data-science-with-compassion Develop a predictive model that leverages Kiva loan features to estimate regional welfare indicators, normalized between 0 (representing poor conditions) and 1 (representing rich conditions), using national social indicators as a training target. Include preprocessing steps such as feature engineering, normalization of national social indicators, handling missing data, and data visualization. Ensure data integrity during joins. Evaluate the model's performance by predicting welfare on a granular, regional level.\n",
      "__________\n",
      "moa-eda-from-a-computational-biologist Perform a domain-specific exploratory data analysis (EDA) of Mechanisms of Action (MoA) data. Execute Principal Component Analysis (PCA) on a gene expression dataset to reduce dimensionality and identify major axes of variation. Determine the number of principal components to use by examining the variance contribution of each component. Apply the Leiden clustering algorithm on t-SNE/UMAP reduced dimensional representations derived from PCA to identify distinct clusters in gene expression data. Cluster based on the first 30 nearest neighbors considering 10 principal components. Evaluate the quality of clustering and explore the differential expression of genes within each cluster.\n",
      "__________\n",
      "why-shapley-is-great-for-understanding-ml-results Discuss and demonstrate the use of Shapley values for interpreting machine learning models by utilizing SHAP (Shapley Additive exPlanations).\n",
      "__________\n",
      "earthquakes-in-greece-exploratory-analysis {'1': 'Extract the Greek earthquake dataset for the period 1901-2018 and load it into a dataframe.', '2': \"Rename the columns 'LATATITUDE (N)', 'LONGITUDE (E)', 'MAGNITUDE (Richter)' to 'Lat', 'Long', 'Magn'.\", '3': \"Perform data cleaning to remove entries with 'magnitude = 0.0' and entries that do not fall within the boundaries of modern Greek territory using geojson for actual Greek borders.\", '4': 'Categorize earthquakes according to the Richter Magnitude Scale into dataframes for classifications such as minor, light, moderate, strong, and major.', '5': 'Visualize the relevant earthquake data on a map using the actual geojson boundaries of Greece.'}\n",
      "__________\n",
      "the-night-fellini-met-miyazaki Implement and run the pretrained image cartoonization model, as described in the Tensorflow implementation of the CVPR2020 paper 'Learning to Cartoonize Using White-box Cartoon Representations', on frames extracted from the specified video clip. Adapt the provided test_code modules for compatibility with Tensorflow 2.0, capture frames from the original video as inputs, and produce cartoonized output frames via inference. No explicit performance metrics provided.\n",
      "__________\n",
      "computer-vision-with-seedlings Develop a computer vision model to classify 12 common species of seedlings in Danish agriculture, ensuring the model distinguishes between cultivated and wild plants. Address target leakage by extracting features pertaining only to plant information, omitting background elements like pebble stones. Employ pre-trained neural networks and evaluate the model based on classification accuracy.\n",
      "__________\n",
      "how-popular-is-kaggle-in-africa {'objective': 'Analyze the engagement and representation of African participants on the Kaggle platform using the 2021 Kaggle survey dataset, with emphasis on the year-over-year growth rate, comparing it to global statistics.', 'methods': ['Descriptive statistical analysis', 'Trend analysis', 'Comparative analysis'], 'metrics': ['Participation rates by African countries', 'Year-over-year participant growth percentages', \"Comparison of Africa's Kaggle participation rate with its share of global population\"]}\n",
      "__________\n",
      "opioids-in-the-us-initial-graphs Perform data cleaning and visualization on the Opioid dataset. Specifically, convert the 'Data Value' column to a float data type and ensure compatibility for graphing. Subsequently, create time-series graphs to analyze trends in Opioid usage over time.\n",
      "__________\n",
      "how-good-does-your-chocolate-taste Perform exploratory data analysis and preprocessing on a chocolate bar ratings dataset, clean the data, rename columns for usability, and handle missing values in features such as bean type. Create new features to improve the predictive performance of a Catboost model trained to predict chocolate ratings, while exploring and utilizing different functionalities of the Catboost library. Evaluate model performance using appropriate metrics.\n",
      "__________\n",
      "moa-keras-kerastuner-best-practices Construct a neural network using Keras capable of multilabel classification for the MoA (Mechanism of Action) prediction competition. Additionally, employ KerasTuner to optimize the neural network's configuration, and apply ensemble methods to improve the final prediction accuracy. Ensure that the data preprocessing includes encoding of categorical features using `StringLookup` and `CategoryEncoding` layers and normalization of numerical features. Evaluate model performance using appropriate metrics for multilabel classification.\n",
      "__________\n",
      "what-s-cooking Develop a multi-class text classification model to predict the cuisine category of a recipe based on its list of ingredients. Use appropriate feature engineering techniques for textual data representation and evaluate the model using relevant metrics such as accuracy or F1-score.\n",
      "__________\n",
      "recommendation-engine-with-networkx Develop a graph-based movie recommendation engine that utilizes the Adamic Adar measure for similarity scoring. Implement TF-IDF to compute movie description similarity and augment the graph with 'Similar_to_this' nodes based on the top 5 similar descriptions per movie. Incorporate these 'Similar_to_this' nodes into the Adamic Adar calculation to refine the recommendations.\n",
      "__________\n",
      "shadow-cornerback-coverage-analysis Analyze the effectiveness of 'Shadow Cornerbacks' in limiting the performance of opposing team's top wide receivers during football games. Use statistical methods to compare the metrics of games with and without active shadowing by the best cornerbacks. Possible metrics for effectivity can include number of receptions, yards gained, touchdowns, and receiver's game rating.\n",
      "__________\n",
      "imagenet-embeddings-rapids-svr-finetuned-models Develop a feature extraction and model selection pipeline using pretrained models from the timm library for a data science task. Initially, extract last layer features from a subset of the 575 available pretrained models and use those features to train a Support Vector Regressor (SVR). Implement a forward model selection algorithm to identify a subset of models that optimizes performance based on Root Mean Square Error (RMSE) metric, by adding models iteratively until no further improvement in RMSE is observed.\n",
      "__________\n",
      "how-to-create-award-winning-data-visualizations Create a data visualization to compare the number of people working in different job positions across various countries using Plotly or a similar graphing library.\n",
      "__________\n",
      "tf-jax-tutorials-part1 None\n",
      "__________\n",
      "world-happiness-index-report Perform hypothesis testing to determine if there is a significant difference in happiness index between two regions. Identify the contributing factors to the happiness index.\n",
      "__________\n",
      "u-s-airbnb-analysis-and-price-prediction Develop a predictive model to estimate Airbnb listing prices in the USA. The model should utilize a sequential neural network with an embedding layer to process the textual listing names, and the outputs of this neural network should be combined with the remaining numeric features using a random forest model in an ensemble fashion. Initial steps include data cleaning (handling missing values and outliers) and exploratory data analysis (EDA), with a focus on distribution analysis for numeric features and location-based analysis to identify pricing patterns across different locations. The performance of the model should be evaluated using appropriate regression metrics such as RMSE or MAE.\n",
      "__________\n",
      "rethinking-cv-strategy-with-visualizations Investigate and compare GroupStratifiedKfold and StratifiedKfold cross-validation strategies in the context of a labeled image dataset with similarities across labels and potential mislabeling. Employ clustering techniques to form image groups and use these groups to assess the validity of GroupStratifiedKfold for model validation. Report on the separation of clusters formed from the image data.\n",
      "__________\n",
      "introduction-to-volcanology-seismograms-and-lgbm Develop a machine learning model to predict the time until the next volcanic eruption using seismic sensor time series data. Ensure proper handling of missing values and utilize LightGBM with cross-validation for model training. Assess model performance using metrics suitable for regression tasks such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), or R-squared (R²).\n",
      "__________\n",
      "german-credit-analysis-a-risk-perspective {'1': 'Explore dataset to identify numerical and categorical variables, and investigate columns with null values for subsequent feature engineering.', '2': 'Perform a gender analysis to determine credit loan applications distribution, age distribution by gender, primary reasons for credit loan applications by gender, number of jobs by gender, and unemployment rates.', '3': 'Segment the dataset into categorical age groups and analyze loan amounts and high-risk loans within each age group.', '4': 'Develop a Neural Network model to predict the risk category (good or bad) of a loan, employing appropriate performance metrics such as accuracy, precision, recall, F1 score, or AUC (area under the ROC curve).'}\n",
      "__________\n",
      "starter-code-eda-and-lgbm-baseline Perform exploratory data analysis (EDA) on pilot distraction dataset to understand the distribution and characteristics of the target variable representing cognitive states (Channelized Attention, Diverted Attention, Startle/Surprise, and baseline). Then, prepare the dataset for modeling and employ a Light Gradient Boosting Machine (LGBM) algorithm to classify samples into one of the four predefined labels (A, B, C, D) corresponding to baseline, Startle/Surprise, Channelized Attention, and Diverted Attention. Evaluate the model's performance using relevant metrics like accuracy, precision, recall, F1-score, and any applicable confusion matrix-derived metrics.\n",
      "__________\n",
      "airbnb-data-analysis Perform a data analysis on the New York City Airbnb dataset focusing on: 1. Distributive statistics and visualizations of global price distribution. 2. Spatial distribution analysis to identify the most expensive zones. Metrics may include mean, median, percentiles, and geospatial clustering measures.\n",
      "__________\n",
      "don-t-be-left-behind-data-science-literacy Analyze the Kaggle Survey 2020 dataset to characterize the subset of respondents who identify as data scientists, including an examination of their work environment, tools used, and daily responsibilities. Report on the demographic, roles, tools employed, and trends among the data scientist respondents. Metrics for analysis could include distribution of roles, popular tools, and the proportion of data scientists in relation to the total number of respondents.\n",
      "__________\n",
      "trending-youtube-video-metadata-analysis Perform data preprocessing and Exploratory Data Analysis (EDA) on the US videos dataset, focusing on understanding key data attributes such as missing values, unique counts, outliers, and time-series trends. Investigate the relationship between the speed at which a video becomes trending and the subsequent growth in video views. Utilize appropriate data visualization techniques to summarize findings and prepare the dataset for data mining to explore factors influencing the growth in video views.\n",
      "__________\n",
      "casestudy-eda-for-cardio-good-fitness Perform exploratory data analysis to profile customers of different treadmill products. Identify characteristics of customers (age, gender, education, marital status, usage, fitness, income, miles) per treadmill model. Analyze relationships between these customer characteristics and treadmill models to generate insights for targeted marketing. Include metrics such as purchase counts, correlation between variables, and distribution measurements.\n",
      "__________\n",
      "the-12-different-types-of-kagglers Using the provided 2017 Kaggle Data Science Survey results, perform data preprocessing to handle missing values and convert categorical features into numerical approximations. Then, calculate correlations between key data fields and execute cluster analysis to identify distinct 'Kaggler' archetypes present within the approximately 16,000 survey respondents. Summarize each identified Kaggler archetype separately, without providing analysis or background information about the dataset itself.\n",
      "__________\n",
      "gender-gap-in-the-kaggle-community Analyze the disparities in salary based on gender across different continents and sub-regions, using a dataset from a Kaggle user survey. Convert salary ranges into numerical averages for better representation, excluding high salary outliers (above $200k per year). Compare mean salaries between genders within each geographical area and assess if there are significant differences. Use statistical methods to ensure any observed difference is significant, providing metrics such as mean salary by continent and sub-region, and by gender, while checking for the representativeness of the sample among genders.\n",
      "__________\n",
      "data-professional-in-small-vs-large-companies Analyze the 2021 Kaggle ML & DS Survey to determine the relationship between company size and the role of a Data Professional. Company size is categorized as XS (0-49 employees), S (50-249 employees), M (250-999 employees), L (1000-9,999 employees), XL (10,000 or more employees). Investigate differences in job positions, expectations, and career opportunities based on company size. Employ descriptive statistics and visualization techniques to summarize findings; use inferential statistics to ascertain if the differences are statistically significant.\n",
      "__________\n",
      "starter-autotel-shared-car-locations Develop a data processing and analysis pipeline to filter out empty parking spots from the AutoTel Dataset, calculate the usage rate of the shared cars, and identify trends in usage rate over time. Ensure to work with the most up-to-date dataset by downloading the latest version from the provided BigQuery dataset link. Measure usage rate as a percentage of the maximum available cars, which is assumed to be 260. Analyze usage patterns for different times to find peak and low usage periods.\n",
      "__________\n",
      "data-science-in-the-cloud-who-wins-the-cloud-war Analyze Kaggle 2020 Survey data to determine the preference of cloud computing platforms among data professionals, and compare it with the overall cloud services market share. Identify trends and insights regarding the use of AWS, GCP, and Azure among the survey respondents. Quantify the overlap of users between these platforms and assess the geographic distribution of the cloud services usage, particularly focusing on India. Calculate and interpret the market share based on the available industry data for Q1 2020.\n",
      "__________\n",
      "ant-colony-optimization-algorithm Implement and refine the Ant Colony Optimization Algorithm to solve the Travelling Salesman Problem (TSP). Define the algorithm with tunable parameters such as ant_count, ant_speed, pheromone_power, distance_power, reward_power, decay_power, and best_path_smell. Incorporate vectorized operations for efficiency, and implement a termination condition based on stop_factor, time, min_time, timeout, or round_trips. Optimize the algorithm by experimenting with the pheromone influence and distance metric (e.g., 1/distance vs. 1/distance^2) to converge on a near-optimal solution.\n",
      "__________\n",
      "roberta-meets-tpus Apply the RoBERTa model to the tweet sentiment extraction challenge, process the competition dataset, and train a model to identify the sentiment of a given tweet. Evaluate the model using the specified evaluation metric.\n",
      "__________\n",
      "house-prices-xgboost None\n",
      "__________\n",
      "a-look-back-at-your-kaggle-journey Develop a data analysis pipeline that accepts a `username` as input and generates time series visualizations to illustrate the user's journey on Kaggle. This includes tracking competition participation, kernel contributions, and discussion engagement, with a focus on interactions such as kernel upvotes, forum post upvotes, and follower count over time.\n",
      "__________\n",
      "bert-tpus-jax-huggingface Train and evaluate a Flax-based Neural Network using JAX on a TPU for natural language processing tasks, utilizing HuggingFace pre-trained models. Ensure the evaluation uses the Root Mean Square Error (RMSE) metric as defined by the 'Common Lit Readability' contest.\n",
      "__________\n",
      "energy-in-the-netherlands-an-introductory-kernel Aggregate and clean the energy consumption data from the three major network administrators in the Netherlands (Enexis, Liander, Stedin) for various years. Ensure the aggregated data properly reflects the correct yearly consumption per zip code group, despite the differences in the grouping of zip codes and potential redefinitions across the years. Handle and correct inconsistencies across different company datasets and missing data (e.g., for the year 2009 for one company). Prepare the dataset for further analysis, which might include tracking energy consumption changes at a zip code level over time.\n",
      "__________\n",
      "what-gets-you-arrested-in-san-francisco Analyze the San Francisco crime dataset to identify the patterns and insights related to crime incidents, including the frequency of crimes by type, temporal patterns, spatial distribution across districts, and arrest outcomes. Employ statistical methods to summarize the dataset's features such as the most common crimes, peak times for crime activity, district-wise crime incidence, and arrest rates. Use appropriate metrics such as percentages for categorical data analysis.\n",
      "__________\n",
      "mechanisms-of-action-what-do-we-have-here {'Perform a multi-label classification to predict multiple targets of the Mechanism of Action (MoA) responses based on gene expression data, cell viability data, Cp type, and treatment details (duration and dose). For evaluation, consider relevant multi-label classification metrics such as Hamming Loss, F1 Score (micro/macro/weighted), or Jaccard Similarity Score.': 'None'}\n",
      "__________\n",
      "contradictory-watson-concise-keras-xlm-r-on-tpu Initialize TPUs and set the number of replicas accordingly. Load and preprocess datasets from CSV files. Encode the datasets into numerical tokens for both training and test data, and perform train-validation split.\n",
      "__________\n",
      "covid-19-world-vaccination-progress Perform data visualization and analysis on the COVID-19 World Vaccination Progress dataset, which includes country-specific vaccination data such as total vaccinations, people vaccinated, daily vaccination numbers, ratios per hundred and per million, and available vaccine types. The analysis should reveal trends in vaccination progress, compare vaccination strategies, and identify leaders in vaccination efforts. Utilize appropriate graphical representations for temporal and spatial patterns, and apply data preparation techniques to ensure the quality and consistency of the dataset. Metrics for analysis are not explicitly defined; however, quantities such as total vaccinations, vaccination rates, and daily changes are implied.\n",
      "__________\n",
      "the-unusual-suspects-2020 Analyze survey data to determine if observed differences in skill and tool usage among data scientists, data engineers, and machine learning engineers are statistically significant using the two-proportions z-test.\n",
      "__________\n",
      "shopee-embedding-visualizations-before-after-inb Compare the TSNE visualizations of validation set embeddings before and after applying the Iterative Neighborhood Blending (INB) technique, and quantify the impact of INB by calculating the change in mean F1 score per label group, as well as the overall validation F1 score improvement.\n",
      "__________\n",
      "how-big-is-french-industry-data-visualization Create a set of data visualizations to analyze the scale and distribution of French industries, including preprocessing of relevant geographical, industrial, and salary datasets. Implement feature engineering and dataset merging where necessary. Follow up with visualizations to interpret industrywide economic patterns, regional economic strengths, and gender pay disparities. Employ appropriate visualization metrics to clearly communicate findings.\n",
      "__________\n",
      "yolo-ensemle None\n",
      "__________\n",
      "whr-2021-eda-and-linear-regression-beginner Analyze the global happiness dataset to assess the impact of GDP per capita, Healthy Life Expectancy (HLE), social support, freedom to make life choices, generosity, and corruption perception on the overall happiness score of a country. Use appropriate statistical or machine learning methods to quantify the relationships among these variables. Implement the analysis using Python and ensure proper interpretation of the results. Evaluate model performance using suitable metrics such as R-squared for regression or accuracy for classification, where applicable.\n",
      "__________\n",
      "introduction-to-financial-mathematics Implement Python functions to calculate compound interest, option pricing, option trading strategies, portfolio hedging, and perform basic risk management calculations. Use libraries such as NumPy for linear algebra, Matplotlib for visualization, and Scipy for optimization and probability distributions.\n",
      "__________\n",
      "what-s-in-a-name-2021-kaggle-survey-competition Conduct a comprehensive analysis of job titles and responsibilities within the U.S. data science field, with additional demographic, technology usage, salary, and experience level insights derived from survey data. Metrics to evaluate may include task frequencies in job descriptions, demographic distributions, technology adoption rates, average salary figures, and years of experience statistics.\n",
      "__________\n",
      "moa-all-rapids Implement an end-to-end data science pipeline using RAPIDS libraries for data preprocessing, model training, and scoring with LogisticRegression models. The objective is to surpass the score of the best known RAPIDS demo within a time frame of less than 10 minutes.\n",
      "__________\n",
      "geospatial-feature-engineering-and-visualization Create new predictive features for California housing data by integrating geospatial information from external datasets. The features to be engineered include: 1) Nearest city name, 2) Distance to the nearest city, 3) Population of the nearest city, 4) Nearest big city (population > 500,000), and 5) Distance to the nearest big city. Implement functions to calculate distances between geographical coordinates using Vincenty's formulae. Clean and merge the provided latitude/longitude and historical population datasets into the existing housing dataset. Additionally, develop visualizations to inspect new features and retrain an XGBoost model to evaluate performance improvements over the previous model.\n",
      "__________\n",
      "eda-and-data-storytelling-on-disney-movies Perform exploratory data analysis (EDA) on the Disney Movie Gross Income Dataset to uncover trends related to the genre and MPAA rating of Disney movies, and how these attributes correlate with the movies' financial performance, specifically using total gross and inflation-adjusted gross as metrics.\n",
      "__________\n",
      "understanding-and-improving-cyclegans-tutorial Implement a CycleGAN model for unpaired image-to-image translation. Train two neural networks for forward and backward transformation between photographic and Monet-styled images. Perform data augmentation using random jittering and flipping. Train on `256 x 256` RGB images normalized to `[-1, 1]`. Exclude labels and image IDs in training data generation. Measure performance using GAN loss for image believability evaluated by the discriminator.\n",
      "__________\n",
      "recreating-gapminder-visualisation-with-bokeh Recreate the visualization similar to that presented by Hans Rosling, illustrating the development of 200 countries over 200 years with respect to health (Life Expectancy in years) and wealth (GDP per capita), using the Bokeh library for interactive data visualization. Ensure the recreation incorporates Bokeh's interactive features and covers all countries and the specified time frame.\n",
      "__________\n",
      "zoomable-circle-packing-via-d3-js-in-ipython Embed D3.js visualizations within an IPython notebook, showcasing the creation of an interactive and dynamic circle-packing visualization based on the 'class' feature of a dataset. The task will involve data preparation of input JSON file, and achieving an interactive visualization that allows zoomable animations. Metrics or specific requirements for evaluation are not explicitly mentioned.\n",
      "__________\n",
      "animation-gan-latent-walk Implement an algorithm to animate a latent walk using a pre-trained generative model. Extract frames by interpolating between points in the latent space, then compile these frames into an animated GIF. Measure success by the visual quality of the generated GIF and the continuity of the transition between frames.\n",
      "__________\n",
      "co2-after-greta Create a model to visualize and compare weekly CO2 levels post-GRETA event, distinguishing between Business As Usual (BAU) trajectory and the IPCC Special Report on 1.5 degrees C pathway. Calculate CO2 concentration rates, plotting them alongside their respective models, and assess progress towards the Paris Agreement goals. Required metrics include the rate of change in CO2 concentration (ppm/yr), deviations from the fixed BAU, and adherence to desired CO2 trajectory as outlined by the IPCC SR1.5, with emphasis on the expected deviations from BAU at the end of specific years (e.g., 2020, 2021, and 2022).\n",
      "__________\n",
      "recommending-music-artists-with-boltzmann-machines Implement a Boltzmann machine for music artist recommendation based on user listening histories from last.fm, assessing performance using accuracy, loss metrics, and subjective testing for recommendation appropriateness.\n",
      "__________\n",
      "building-resnet34-from-scratch-using-pytorch Implement the ResNet34 architecture using PyTorch, detailing the specific components such as convolutional blocks, residual blocks, layer configurations, and classifier block. Ensure that the implementation allows for creating a ResNet34 model.\n",
      "__________\n",
      "analysing-indian-recipes Perform exploratory data analysis on the Indian recipes dataset to determine the distribution of dishes among Indian states. Replace all occurrences of '-1' with NaN to clean the data, and then visualize the frequency of dishes by state. Use appropriate data visualization libraries such as matplotlib.pyplot and seaborn.\n",
      "__________\n",
      "train-model-with-tensorflow-cloud Configure and deploy a TensorFlow model training job on Google Cloud using TensorFlow Cloud API, providing compatibility for transitioning from local Kaggle notebook training to distributed training in Google Cloud, ensuring necessary Google Cloud credentials are set up.\n",
      "__________\n",
      "swinformer-cutmix-amp-accelerate-w-b Implement a Swin Transformer model using the 'timm' library in PyTorch for a given computer vision problem. The model to be used is 'swin_small_patch4_window7_224' with pre-trained weights on ImageNet. Ensure the implementation is compatible with various vision tasks, particularly image classification. Evaluate the model's performance using relevant metrics for image classification, such as accuracy, precision, recall, and F1-score.\n",
      "__________\n",
      "a-look-at-sentiment-on-the-kaggle-forums Rebase sentiment classification scores from a bipolar scale to a unipolar scale where -1 represents the most negative sentiment and +1 represents the most positive sentiment, and analyze sentiment trends over time in Kaggle forum posts.\n",
      "__________\n",
      "model-cards Learn about model cards, their purpose, and contents, and then apply this knowledge to real-world examples by creating model cards for specific AI systems.\n",
      "__________\n",
      "hugging-face-transformers-get-started Utilize the BERT architecture from the transformers library for NLP tasks such as Named Entity Recognition, Sentiment Analysis, Language Modeling, and Question Answering. Employ pretrained models in PyTorch or TensorFlow, understand the tokenizer usage, and differentiate between token-level and aggregated sequence representation outputs for specific downstream applications.\n",
      "__________\n",
      "maps-of-nyc-airbnbs-with-python Perform a spatial analysis of NYC Airbnb listings, requiring data ingestion and visualization. Specifically, 1) aggregate Airbnb listing data by borough and generate bar charts, 2) spatially plot neighborhoods using GeoPandas and a base map from NYC Open Data, 3) resolve issues with mismatching neighborhood names causing missing data, and 4) identify Airbnb listings that satisfy certain criteria related to proximity to Yankee Stadium and subway stations. Metrics for the spatial analysis may include distance calculations and density measures, although specific metrics are not provided in the text.\n",
      "__________\n",
      "the-convolutional-classifier Develop a convolutional neural network (CNN) image classifier using Keras that distinguishes between images of cars and trucks. Implement transfer learning by reusing the base of a pretrained model and attaching an untrained dense head for the classification task. Apply data augmentation techniques to enhance the dataset, and employ feature extraction methods to identify relevant visual features. Measure the classifier's performance using relevant metrics such as accuracy.\n",
      "__________\n",
      "patterns-of-colorectal-cancer-image-clustering Perform unsupervised clustering and supervised clustering on the Kather_texture_2016_image_tiles_5000 dataset to classify different types of colorectal cancer tissues. Utilize image statistics per class to inform the clustering process, with an emphasis on the relationship between image statistics and overall intensity distribution statistics. Ensure the dataset is composed of 150x150 pixel grayscale images, with 8 classes of cancer tissues. Evaluate the performance of clustering algorithms using appropriate metrics such as silhouette score for unsupervised clustering and accuracy, precision, recall, and F1-score for supervised clustering.\n",
      "__________\n",
      "a-tour-of-the-oil-industry Predict short-term share prices for selected oil companies using machine learning techniques such as linear regression, cluster analysis, and Random Forest Regression. Evaluate the models using appropriate metrics such as mean squared error (MSE), mean absolute error (MAE), or coefficient of determination (R-squared). Utilize datasets containing daily oil prices and daily share prices of specified oil companies.\n",
      "__________\n",
      "alone-in-the-woods-using-theil-s-u-for-survival Perform exploratory data analysis on a dataset of 8124 mushrooms with 22 attributes (excluding the `class` column) to determine the variance of each feature. Identify and remove any feature(s) with zero variance as they do not contribute to the classification task.\n",
      "__________\n",
      "2xyolov5l6-tracking-lb-0-678-private-0-722 None\n",
      "__________\n",
      "quantify-the-madness-a-study-of-competitiveness Develop a model to quantify the competitiveness of a college basketball game using play-by-play data. The competitiveness score should reflect the intensity of the game and is based on the following conditions: a close final score (3 points difference), a close score within the final 3 minutes (2 points difference), occurrence of overtime, and the number of lead changes during the game (more than 20 in total, more than 10 in the second half, or more than 2 in the last 3 minutes). The model should be trained using historical game data from both Men's and Women's tournaments from the past 6 seasons. Metrics for evaluating the model's performance could include accuracy in reflecting known competitive games and the ability to generalize beyond the training data.\n",
      "__________\n",
      "mental-health-in-tech Analyze the mental health condition prevalence among tech professionals in comparison to the general U.S. adult population, and assess the trend in gender distribution over time within the tech industry based on survey data. Calculate the rate of mental health conditions among tech professionals and compare it with national statistics. For the gender analysis, process the survey data to produce a time-series plot displaying the changes in gender representation in the tech industry. Ensure to identify and include key demographic categories within the dataset for detailed examination.\n",
      "__________\n",
      "meta-kaggle-competition-shake-up Compute the shake-up metric for selected Kaggle competitions. The metric for standard shake-up is the mean difference in ranks between public and private leaderboards normalized by the number of participating teams, specifically mean(abs(private_rank - public_rank) / number_of_teams). Additionally, calculate the shake-up for the top 10% of teams based on the public leaderboard using the same formula. Exclude competitions with specific criteria such as having no private leaderboard or those that award no points. Ensure the dataset is filtered to only include Featured, Recruitment, and Research competitions with Shake-up > 0 and UserRankMultiplier > 0.\n",
      "__________\n",
      "how-long-does-it-take-to-be-gm None\n",
      "__________\n",
      "adversarial-rainforest Construct an adversarial validation model to determine the level of discrepancies between training and testing datasets using FFT features, and apply SHAP values to identify the most significant features responsible for the discrepancies. Evaluate the adversarial model using the AUC metric and ensure it utilizes GPU acceleration for both model training and SHAP value calculation.\n",
      "__________\n",
      "a-deep-learning-of-deep-learning Analyze the 2019 Kaggle ML & DS Survey data to characterize deep learning practitioners. Determine demographic patterns, compare career trajectories and salaries with non-DL practitioners, assess resource requirements for DL practice, and speculate on future implications for industries and methodologies. Use responses to Q24 to differentiate between DL and non-DL practitioners, excluding individuals who did not answer, chose None, or Other. Report on the number of DL versus non-DL practitioners identified.\n",
      "__________\n",
      "see-the-flow-of-bikes Analyze the flow of bicycles within the Bike Share Toronto Service to determine if bicycles primarily make round trips or if there are distinct flows from one region to another. To do so, perform the following: segment data by weekend and non-weekend days; group stations by proximity to form 20 distinct regions; aggregate journey counts between stations for defined time periods (day, week, month, year) focusing on data from the year 2018; create a directed graph where nodes represent stations or regions, and edges represent the net flow of trips between nodes within a time period, excluding self-loops (trips starting and ending at the same station). Compute and analyze the balance of outgoing and incoming flows for each node. Utilize the stations' GPS coordinates for clustering and ensure data cleaning and preprocessing, specifically with the 'trip_start_time' column.\n",
      "__________\n",
      "lego-minifigures-pytorch-and-neptune-ai-template Use PyTorch to implement image classification with a pretrained MobileNetV2 model to identify LEGO Minifigure classes, and log experiments using Neptune.ai. Evaluate the model performance using appropriate image classification metrics.\n",
      "__________\n",
      "classification-how-imbalanced-is-imbalanced Evaluate and compare various classification metrics on a synthetic binary classification dataset with imbalanced class ratios, utilizing Scikit-learn's RandomForestClassifier with default settings. Metrics to assess include accuracy_score, balanced_accuracy_score, average_precision_score, recall_score, f1_score, and area under the ROC curve. Perform test/train splits using StratifiedShuffleSplit to maintain class proportion.\n",
      "__________\n",
      "the-5-types-of-kagglers Perform k-means clustering on the Kaggle survey dataset using specified features. Features include 'num_langs', 'num_algs', 'num_sources', 'age_class', 'degree', 'years_coding_class', 'years_ml_class', 'student', and 'ml_used_at_job'. These features are a mix of discrete, ordinal, and binary variables. Identify 5 distinct clusters representing different types of Kagglers. Analyze the resulting clusters with respect to Kagglers' occupation, expenditure on ML/cloud services, gender distribution, and their geographical representation from the top 15 respondent countries.\n",
      "__________\n",
      "magic-2-an-explanation Implement and evaluate an algorithm to remove background noise from signal samples in the given dataset, with a focus on signals with a wide frequency range that are split into overlapping bands. Ensure to correct for the independent normalization (mean=0, std=1) applied to each image in a sample. Assess the effectiveness of the noise removal method, potentially using metrics such as Signal-to-Noise Ratio (SNR) improvement, if relevant and available.\n",
      "__________\n",
      "tutorial-3d-pca-video-animation Implement a 3D Principal Component Analysis (PCA) on the Wisconsin Breast Cancer Dataset ($\text{WBCD}$), reducing the feature space from $\text{R}^{10}$ to $\text{R}^{3}$, and create a biplot animation using the **proj3d** and **Axes3D** modules from the *mplot3d* library. There are no specific metrics required for this task.\n",
      "__________\n",
      "exploring-data-analytics-in-africa Analyze the 2021 Kaggle Survey dataset to determine the demographic distribution of data science professionals in Africa, the prevalence of data analytics across different industries including company counts and employee base, the extent of machine learning adoption, the analytics tools used (programming languages, databases, IDEs, hardware, visualization tools, BI tools, and cloud computing services), and the typical activities of data analysts within these organizations.\n",
      "__________\n",
      "1d-cnn-densenet1d Implement a one-dimensional version of the DenseNet architecture in PyTorch, ensuring compatibility with the 'timm' model interface by including methods such as `.forward_features(x)`, `.get_classifier()`, and `.reset_classifier()`. No specific metrics are outlined for evaluation.\n",
      "__________\n",
      "image-recognition-from-scratch-1 Implement a linear spatial filtering algorithm for image preprocessing that reduces the amount of data without significant loss of information. This involves using a kernel to convolve with the image data, applying weighted sums over targeted pixel neighborhoods, adding padding to the image to handle edge pixels, and outputting the filtered image with smaller data size. Evaluate the algorithm's performance qualitatively by inspecting the filtered image.\n",
      "__________\n",
      "the-success-story-compete-win-with-kaggle-data Analyze the Kaggle Machine Learning and Data Science Survey dataset to quantify the global contribution of Small and Medium Enterprises (SMEs) in the data science landscape, focusing on the percentage share of individuals working in SMEs. Identify trends, specifically any notable shifts during the Covid-19 pandemic period, and measure the resilience of the SME sector comparatively to larger firms.\n",
      "__________\n",
      "bike-sharing-in-boston-vs-covid19 Perform an exploratory data analysis to compare BlueBikes usage between 2019 and 2020 to determine the impact of COVID-19 on bike sharing patterns. Include univariate analysis and handle missing personal information data from 2020.\n",
      "__________\n",
      "plotly-avatar-the-last-airbender-analysis None\n",
      "__________\n",
      "how-long-it-takes-to-win-1st-on-kaggle Perform an analysis to measure the average time span from registration to a first-place win for participants (both as solo competitors and as team leaders) in Kaggle competitions that offer financial rewards or job opportunities. Exclude tutorial and non-rewarded competitions. Additionally, assess the trend over time to ascertain if winning has become easier, potentially by examining shared resources aiding newcomers. Required metrics for the analysis are mean time in days and any statistical measure indicating the change in difficulty over time.\n",
      "__________\n",
      "shifterator-analysis-on-animal-crossing-reviews Perform sentiment analysis on the Animal Crossing reviews dataset using the Shifterator package to compare frequency and usage of words in negative and positive reviews. Clean the dataset by removing punctuation, stop words, and converting text to lowercase before calculating word frequencies.\n",
      "__________\n",
      "wind-power-forecasting-using-tensorflow Predict the power output of a windmill over a 15-day forecast period using time-series analysis with TensorFlow. Preprocess the dataset by converting the 'Unnamed: 0' column to datetime format and remove duplicate pitch angle columns after validation.\n",
      "__________\n",
      "the-world-belongs-to-those-who-read {'Data Analysis': ['Identify the authors with the highest number of bestsellers in the dataset.', 'Determine the predominant genre of bestsellers for each year in the dataset.', 'Analyze the trend in the mean price of bestsellers over the years.', 'Calculate the mean price of bestsellers within each genre.', 'Find the books with the most reviews.', 'Compare the number of reviews across genres.', 'List the books with the highest user ratings.', 'Examine how the user ratings have evolved over the years.', 'Investigate if there is a correlation between user rating and book price.', 'Identify common words in the titles of bestsellers.'], 'Predictive Modeling': ['Develop a model to predict the genre of a book.', 'Develop a model to forecast the price of a book.', 'Develop a model to estimate the popularity of a book, as measured by reviews.']}\n",
      "__________\n",
      "battle-of-the-boosting-algos-lgb-xgb-catboost {'1': 'Classify images using XGBoost, LightGBM, and Catboost on the Fashion MNIST dataset with a benchmark of 60,000 rows and 784 features.', '2': 'Predict New York City Taxi fares using XGBoost, LightGBM, and Catboost with a benchmark of 60,000 rows and 7 features.', '3': 'Predict New York City Taxi fares on a larger scale using XGBoost, LightGBM, and Catboost with a massive dataset benchmark of 2 million rows and 7 features.'}\n",
      "__________\n",
      "celebrity-face-swap Develop a simple face swapping algorithm using provided facial landmarks. This includes implementing image warping with piecewise-affine transforms, and seamless image integration using Poisson blending. Evaluate the algorithm's ability to produce realistic faces in new poses by warping a random frontal face texture across different shape clusters identified by applying K-means clustering to the 2D facial landmark shapes.\n",
      "__________\n",
      "mlb-final-1 None\n",
      "__________\n",
      "1-solution-pid-controller-matching-v1 Develop an algorithm to match test data by predicting pressure (p_t) from inverted PID controllers where I = 0 and D = 0, using known discrete values for parameters alpha (k_p) and target (k_t). Exclude data from the expiratory phase of every breath and the first value of each breath due to noise. After identifying the correct parameter combination, calculate the alignment with discrete pressure values and minimize the sum of absolute errors between the rounded predicted pressure and the actual pressure data.\n",
      "__________\n",
      "a-gentle-introduction-to-wavelet-for-data-analysis Apply a Continuous Wavelet Transform using the 'scaleogram' Python module to a 1D time-ordered dataset to generate a scaleogram for data visualization. The scaleogram should represent periodicity on the Y-axis and time on the X-axis, with signal variation amplitude encoded in the scaleogram's intensity. The goal is to localize periodic variations in the data and analyze them at multiple resolutions. Include frequency or period labels on the axes for interpretability.\n",
      "__________\n",
      "mental-health-plotly-interactive-viz None\n",
      "__________\n",
      "making-perfect-chai-and-other-tales Analyze the YouTube performance data of the Chai Time Data Science podcast episodes to identify patterns correlating with successful episodes, which are defined by high viewership, viewer retention, and contribution to new channel subscriptions. Determine strategies that can enhance audience reach specifically on YouTube, such as the effective release scheduling of mini-CTDS series and tailoring content to resonate with data science beginners, and assess their potential impact. Key performance metrics to focus on include view counts, watch duration, and subscriber growth.\n",
      "__________\n",
      "data-analysis-of-rio-de-janeiro-olympics-2016 Visualize the relationship between athlete heights and weights for team ball sports at the Rio de Janeiro Olympics 2016 using seaborn's relplot function, ensuring that the dataset is filtered for the year 2016 and relevant sports. Evaluate the correlation between height and weight using appropriate statistical metrics.\n",
      "__________\n",
      "transformers-course-chapter-2-tf-torch Understand and replicate the functionality of the Hugging Face Transformers library's `pipeline()` function, focusing on preprocessing, model inference, and postprocessing for NLP tasks using both PyTorch and TensorFlow. Compare and contrast the implementations in PyTorch and TensorFlow.\n",
      "__________\n",
      "bank-marketing-analysis Develop a data science model to predict the outcome of marketing campaigns for individual customers and identify the influencing factors, using banking marketing campaign data. Additionally, perform customer segmentation to determine profiles more likely to subscribe to term deposits, thereby facilitating the creation of targeted marketing campaigns. Evaluate the model's performance using appropriate metrics such as accuracy, precision, recall, and F1 score for the predictive task, and silhouette score for the clustering task.\n",
      "__________\n",
      "keras-neural-network-a-hitchhiker-s-guide-to-nn Construct and optimize an artificial neural network model to predict passenger survival on the Titanic with Keras API for TensorFlow 2. Perform systematic hyperparameter tuning using GridSearch and cross-validation, and analyze model quality using evaluation metrics such as the confusion matrix. Include feature analysis, feature engineering, and data preparation steps.\n",
      "__________\n",
      "2-encourage-diversity-reduce-bias-cola Develop a framework to quantify and mitigate gender bias in job descriptions. Use bag of words and dictionary approaches to identify gender-charged language. Apply normalization techniques to gauge the level of bias and visualize the distribution. Conduct simulation experiments to validate hypotheses regarding the impact of reduced bias on job application rates. Potential metrics include frequency distributions, category classifications of bias level, and applicant response rates in simulations.\n",
      "__________\n",
      "video-games-sales-analysis-and-visualization Perform data cleaning by removing incomplete entries from the video game sales dataset, particularly for the year 2016. Then, conduct statistical analysis and visualization of the cleaned dataset to answer specific questions about video game sales. Ensure to utilize appropriate visualization techniques for displaying various statistics. Additionally, identify and implement suitable metrics for evaluating the analysis, such as sales figures, trends, or patterns.\n",
      "__________\n",
      "understanding-the-extent-of-police-abuse-in-the-us Analyze the relationship between firearm accessibility and the incidence of fatal shootings during police encounters in the United States, differentiating between cases of police and civilian use of firearms. Develop a quantitative measure of bias in police shootings, considering racial demographics and compare the presence of a firearm in incidents involving different racial groups. Ensure the analysis is multidimensional and addresses the potential influence of age and state policies on shooting incidents. Employ appropriate statistical techniques to discern patterns and biases, and report findings with objective metrics.\n",
      "__________\n",
      "time-series-anomaly-detection Perform anomaly detection on the NYC Taxi Demand time series data using the Isolation Forest algorithm. Preprocess the data by checking for missing values and ensuring correct data types. Consider feature engineering to derive additional information from the existing data. Evaluate anomalies based on the average path length in the isolation tree, a measure of normality.\n",
      "__________\n",
      "tutorial-on-reading-large-datasets Compare different methods and file formats for reading and handling large datasets, specifically using the Riiid! Answer Correctness Prediction dataset.\n",
      "__________\n",
      "the-rise-of-data-science-interest-in-india Analyze Kaggle survey responses of young data science aspirants from India to understand their current state in the field by exploring multiple thematic dimensions of the data.\n",
      "__________\n",
      "dutch-electricity-eda-fs-clustering-maps Perform data analysis to evaluate changes in yearly total energy consumption, household electricity production, and smartmeter adoption over time at the country level. Use a pivot table to aggregate energy parameters by city and year, excluding the year 2009 due to incomplete data. Quantify the average annual electricity usage per household and analyze the linear increase in household electricity production and the exponential growth in smartmeter installations. Metrics to consider may include total energy consumption, number of connections, average electricity use per connection, number of smartmeters, and household energy production, all as functions of time.\n",
      "__________\n",
      "mnist-2d-t-sne-with-rapids Benchmark the performance of t-SNE algorithm implementation using Rapids library against the SKLEARN implementation, specifically recording the time taken for dimensionality reduction on MNIST dataset. Compare and report the speedup achieved by the GPU-accelerated version.\n",
      "__________\n",
      "team-merged-ensemble-fixednewmodelsexp029nonmean None\n",
      "__________\n",
      "how-unique-are-you-on-kaggle-get-your-score-here Quantify the uniqueness of a user's survey responses compared to others in the Kaggle survey dataset by one-hot encoding categorical responses, normalizing the vectors to unit norm, computing the cosine similarity using dot products, and calculating the mean angular distance to all other response vectors. Assign a uniqueness score where lower means more unique. Determine the rank of the user based on uniqueness score relative to others.\n",
      "__________\n",
      "girls-rock-data-science Analyze Kaggle's 2020 Data Science Survey data focusing on the gender distribution, specifically the proportion of users identifying as women.\n",
      "__________\n",
      "us-elections-study-with-enriched-data-estimation Analyze American election results using one-way analysis (bar graphs, geographical maps) and multi-way analysis (Gaussian Mixture clustering, PCA), and predict county-level party votes. Include data preparation (loading, merging) and enrichment (adding demographic data). Measure success by the accuracy of the vote prediction.\n",
      "__________\n",
      "africai Analyze the demographics of the African community with a focus on gender representation, using results from the Kaggle survey, to understand the demographic distribution and potential in Africa for AI research and development.\n",
      "__________\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = json.load(open('./data/kaggle_meta/all_task_procs.json'))\n",
    "\n",
    "for x in data:\n",
    "    print(x, data[x])\n",
    "    print('_'*10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a0135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
